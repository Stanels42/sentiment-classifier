{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classifer\n",
    "The goal is to make a prograom that can guess the sentiment of a given sentence bassed on others. My dataset is that of Reddit comments and I am using the number of upvotes as the mesurement of sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Length:  1010826\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv')\n",
    "print('File Length: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>962320</th>\n",
       "      <td>0</td>\n",
       "      <td>Faster.</td>\n",
       "      <td>pash1k</td>\n",
       "      <td>CFB</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10</td>\n",
       "      <td>2013-10-04 05:23:17</td>\n",
       "      <td>\"Almost like a jet taking off... from an aircr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174624</th>\n",
       "      <td>0</td>\n",
       "      <td>Correct, but if you want to crack a walnut a p...</td>\n",
       "      <td>thedugong</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-11 23:19:18</td>\n",
       "      <td>So are nuclear ICBMs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595587</th>\n",
       "      <td>1</td>\n",
       "      <td>It was the best name they had that started wit...</td>\n",
       "      <td>LUSTY_BALLSACK</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>2015-07-07 05:47:27</td>\n",
       "      <td>why companys always throw away cool project na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493873</th>\n",
       "      <td>1</td>\n",
       "      <td>You obviously didn't try hard enough.</td>\n",
       "      <td>Colonel_of_Wisdom</td>\n",
       "      <td>headphones</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>2016-01-23 03:26:27</td>\n",
       "      <td>Sadly they don't fit onto the q701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270816</th>\n",
       "      <td>0</td>\n",
       "      <td>Your stunning lack of details, insights and fa...</td>\n",
       "      <td>Funklestein</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2016-07-01 17:58:40</td>\n",
       "      <td>And now I know you don't know what you're talk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                            comment  \\\n",
       "962320      0                                            Faster.   \n",
       "174624      0  Correct, but if you want to crack a walnut a p...   \n",
       "595587      1  It was the best name they had that started wit...   \n",
       "493873      1              You obviously didn't try hard enough.   \n",
       "270816      0  Your stunning lack of details, insights and fa...   \n",
       "\n",
       "                   author      subreddit  score  ups  downs     date  \\\n",
       "962320             pash1k            CFB      3    3      0  2013-10   \n",
       "174624          thedugong      worldnews      1   -1     -1  2016-10   \n",
       "595587     LUSTY_BALLSACK   pcmasterrace      1    1      0  2015-07   \n",
       "493873  Colonel_of_Wisdom     headphones      5    5      0  2016-01   \n",
       "270816        Funklestein  todayilearned      0    0      0  2016-07   \n",
       "\n",
       "                created_utc                                     parent_comment  \n",
       "962320  2013-10-04 05:23:17  \"Almost like a jet taking off... from an aircr...  \n",
       "174624  2016-10-11 23:19:18                              So are nuclear ICBMs.  \n",
       "595587  2015-07-07 05:47:27  why companys always throw away cool project na...  \n",
       "493873  2016-01-23 03:26:27                 Sadly they don't fit onto the q701  \n",
       "270816  2016-07-01 17:58:40  And now I know you don't know what you're talk...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  comment  score\n",
      "666543     \"What's wrong with complimenting her body!!??\"    192\n",
      "165755  No no obviously they should have suck it in an...      6\n",
      "863251                                        marssantoso      1\n",
      "446770  No it was sheer brilliance and great game read...      1\n",
      "295425  It's ok, guys, Erdogan is just taking some pre...      2\n",
      "934281         TL;DR kid gets what he wants for Christmas      1\n",
      "31108                           I thought the same thing.      6\n",
      "88900                                    Alllllmost there      1\n",
      "919501                          Are you an authoritarian?      6\n",
      "675009                         Chestbrah lookin' massive!      8\n",
      "Length of the Data Field:  34998\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df.sample(35000))\n",
    "df = df[['comment', 'score']]\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.sample(10))\n",
    "print('Length of the Data Field: ', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my function I am using to decide sentiment. Current the bounds are at -2 and 10 for negitive and positive respectivly. Ther values have to be fairly low due to the fact that such a large portion of the dataset contains values around or at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(val):\n",
    "    if val > 10:\n",
    "        return 2\n",
    "    if val < -2:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  comment  score\n",
      "510166               I was born 9 months after a Tuesday.      1\n",
      "545416               Kira Yamato vs ~~Tusk~~ Kira Yamato.      1\n",
      "702925  Yeah, who cares about the people that actually...      1\n",
      "408173                    U mean every Sunday of my life?      1\n",
      "367612  TRP claims to have predicted that, you hyperga...      1\n",
      "678219  sigh... if only we had european style hate spe...      0\n",
      "564128  You guys look like you blow a load onto each o...      1\n",
      "81540   You're grossing me out with your justification...      1\n",
      "246371                                    GGG Slave Owner      1\n",
      "821384   Well, *that's* a helpful and insightful comment.      1\n"
     ]
    }
   ],
   "source": [
    "df['score'] = df['score'].apply(sentiment)\n",
    "print(df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['comment'].iloc[:30000]\n",
    "test_comments = df['comment'].iloc[30000:]\n",
    "scores = df['score'].iloc[:30000]\n",
    "test_scores = df['score'].iloc[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "comments = tokenizer.texts_to_sequences(comments)\n",
    "\n",
    "print(type(comments[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = tokenizer.sequences_to_matrix(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(type(comments))\n",
    "print(comments.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = tokenizer.texts_to_sequences(test_comments)\n",
    "test_comments = tokenizer.sequences_to_matrix(test_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(700, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(400, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of GPUS: 0\n"
     ]
    }
   ],
   "source": [
    "print('Num of GPUS:', len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_y = keras.utils.to_categorical(scores,3)\n",
    "comment_x = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "24000/24000 [==============================] - 23s 944us/sample - loss: 0.5332 - accuracy: 0.8542 - val_loss: 0.4912 - val_accuracy: 0.8568\n",
      "Epoch 2/5\n",
      "24000/24000 [==============================] - 27s 1ms/sample - loss: 0.4534 - accuracy: 0.8543 - val_loss: 0.5213 - val_accuracy: 0.8565\n",
      "Epoch 3/5\n",
      "24000/24000 [==============================] - 23s 956us/sample - loss: 0.2276 - accuracy: 0.9204 - val_loss: 0.7098 - val_accuracy: 0.8162\n",
      "Epoch 4/5\n",
      "24000/24000 [==============================] - 37s 2ms/sample - loss: 0.0742 - accuracy: 0.9768 - val_loss: 1.1801 - val_accuracy: 0.8297\n",
      "Epoch 5/5\n",
      "24000/24000 [==============================] - 27s 1ms/sample - loss: 0.0415 - accuracy: 0.9881 - val_loss: 1.3305 - val_accuracy: 0.8232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f754b114f60>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(comment_x, comment_y,\n",
    "         batch_size=35,\n",
    "         epochs=5,\n",
    "         validation_split=0.2,\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel that there is deffiently something wrong with my model. The fact that it is currently scoring a 98% accuracy I find a little strange. The one reason I can see is that because of the way that I devide my data. The model could be looking for just a few keywords that it can elimenate. Either that or some user error on my behalf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4998/1 - 2s - loss: 0.6454 - accuracy: 0.8211\n",
      "\n",
      "Test accuracy: 0.8211284\n"
     ]
    }
   ],
   "source": [
    "test_scores = keras.utils.to_categorical(test_scores,3)\n",
    "test_loss, test_acc = model.evaluate(test_comments, test_scores, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "After checking the accuarcey I am a little more confident in my model. I never really expected this to be a ground breaking data set. Any dataset that looks at comments espiceally those on Reddit and takes the Karma into account need to do some searous vetting before hand. Most of the time a comment will fail to gain any traction and on a site where everything is displayed based on popularity at a given time it is very easy for information to be lost. I've run the traing several times and have gotten simular results to where the training gets an accuracy score of around 98% and the actual test accuarcy is closer to 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLDR: Timing is more important to successful comments on Reddit then content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}